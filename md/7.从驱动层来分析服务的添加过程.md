## 从驱动层来分析服务的添加过程
#### ServiceManager 
##### 进程成为进程管理者
```c
int binder_become_context_manager(struct binder_state *bs)
{
  return ioctl(bs->fd, BINDER_SET_CONTEXT_MGR, 0);
}
```
看一下怎么成为管理者的BINDER_SET_CONTEXT_MGR
```c
static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
{
    ...
	switch (cmd) {
	case BINDER_SET_CONTEXT_MGR:
		ret = binder_ioctl_set_ctx_mgr(filp);
		if (ret)
			goto err;
		break;

	}
	return ret;
}

// 静态变量
static struct binder_node *binder_context_mgr_node;

static int binder_ioctl_set_ctx_mgr(struct file *filp)
{
	int ret = 0;
	// 进程调用binder_open的时候会创建并保存一份binder_proc
	struct binder_proc *proc = filp->private_data;
	kuid_t curr_euid = current_euid();

    // 管理者只有一个（只能被设置一次）
	if (binder_context_mgr_node != NULL) {
		goto out;
	}
	if (uid_valid(binder_context_mgr_uid)) {
	 ...
	} else {
		binder_context_mgr_uid = curr_euid;
	}
	
	// 静态变量，并且在内核区，所以整个系统起来之后，这个变量只有一个
	binder_context_mgr_node = binder_new_node(proc, 0, 0);
	if (binder_context_mgr_node == NULL) {
		ret = -ENOMEM;
		goto out;
	}
    ...
	return ret;
}

// 创建一个红黑树的节点
static struct binder_node *binder_new_node(struct binder_proc *proc,
					   binder_uintptr_t ptr,
					   binder_uintptr_t cookie)
{
    // 第一次进来这里为null
	struct rb_node **p = &proc->nodes.rb_node;
	struct rb_node *parent = NULL;
	struct binder_node *node;

    ....// 省略添加过程
    
    // 开辟一个节点空间
	node = kzalloc(sizeof(*node), GFP_KERNEL);
	if (node == NULL)
		return NULL;
	// 数量+1
	binder_stats_created(BINDER_STAT_NODE);
	
    // 操作红黑树
	rb_link_node(&node->rb_node, parent, p);
	// 改变红黑树的颜色
	rb_insert_color(&node->rb_node, &proc->nodes);
	...
	// 赋值变量
	node->proc = proc;
	// 因为 binder_new_node(proc, 0, 0) 这两个地址目前都是0 
	node->ptr = ptr;
	node->cookie = cookie;
	node->work.type = BINDER_WORK_NODE;
	...
	return node;
}

```
ServiceManager成为管理者是因为，在内核空间开辟了一个静态的binder_node的根节点，这个binder_node里面存了进程（当前进程ServiceManager）的binder_proc

##### binder_looper 循环等待
```c
void binder_loop(struct binder_state *bs, binder_handler func)
{
    ...
    bwr.write_size = 0;
    bwr.write_consumed = 0;
    bwr.write_buffer = 0;
    readbuf[0] = BC_ENTER_LOOPER;
    binder_write(bs, readbuf, sizeof(uint32_t));
    ...
}

int binder_write(struct binder_state *bs, void *data, size_t len)
{
    struct binder_write_read bwr;
    int res;
    
    // 指令的长度
    bwr.write_size = len;
    bwr.write_consumed = 0;
    // 写的数据 BC_ENTER_LOOPER 
    bwr.write_buffer = (uintptr_t) data;
    bwr.read_size = 0;
    bwr.read_consumed = 0;
    bwr.read_buffer = 0;
    res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);
    ...
    return res;
}

// 进入binder驱动
static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
{
    ...
    struct binder_thread *thread;
    // 从 binder_proc 获取 binder 线程
    // 也就是从红黑树中获取，没有就置为当前进程的id
    thread = binder_get_thread(proc);
  
    switch (cmd) {
    case BINDER_WRITE_READ:
        // filp：binder句柄
        // cmd：BINDER_WRITE_READ
        // arg ：bwr里面有一个 BC_ENTER_LOOPER
        ret = binder_ioctl_write_read(filp, cmd, arg, thread);
        if (ret)
            goto err;
        break;
    }
    return ret;
}

static int binder_ioctl_write_read(struct file *filp,
				unsigned int cmd, unsigned long arg,
				struct binder_thread *thread)
{
	int ret = 0;
	// 拿binder_proc
	struct binder_proc *proc = filp->private_data;
	// 拿指令 这个是BINDER_WRITE_READ 用处不大，主要是移动指针
	unsigned int size = _IOC_SIZE(cmd);
	void __user *ubuf = (void __user *)arg;
	struct binder_write_read bwr;
   
   // 拷贝一份ubuf 到 bwr
	if (copy_from_user(&bwr, ubuf, sizeof(bwr))) {
		goto out;
	}

    // 需不需要写 binder_write里面 
    // bwr.write_size = len
    // bwr.read_size = 0 
    // 有写没有读
	if (bwr.write_size > 0) {
	   // 进入这里参数注意一下
	   // proc：ServiceManager的binder_proc
	   // thread:ServiceManager的进程
	   // write_buffer：BC_ENTER_LOOPER
	   // write_size：sizeof(BC_ENTER_LOOPER)
		ret = binder_thread_write(proc, 
		              thread,
					  bwr.write_buffer,
					  bwr.write_size,
					  &bwr.write_consumed);
		trace_binder_write_done(ret);
	 ...
	}
out:
	return ret;
}


static int binder_thread_write(struct binder_proc *proc,
			struct binder_thread *thread,
			binder_uintptr_t binder_buffer, size_t size,
			binder_size_t *consumed)
{
	uint32_t cmd;
	// BC_ENTER_LOOPER
	void __user *buffer = (void __user *)(uintptr_t)binder_buffer;
	// 偏移量取数据，可以多个指令
	void __user *ptr = buffer + *consumed;
	void __user *end = buffer + size;

	while (ptr < end && thread->return_error == BR_OK) {
		...
		switch (cmd) {
		case BC_ENTER_LOOPER:
	        // 改一下这个状态
			thread->looper |= BINDER_LOOPER_STATE_ENTERED;
			break;
		} break;
	}
	return 0;
}
```
binder_looper首先给驱动发一下BC_ENTER_LOOPER的指令然后改变线的状态
```c
thread->looper |= BINDER_LOOPER_STATE_ENTERED
```
binder_looper接着往下执行
```c
void binder_loop(struct binder_state *bs, binder_handler func)
{
    struct binder_write_read bwr;
    uint32_t readbuf[32];
    bwr.write_size = 0;
    bwr.write_consumed = 0;
    bwr.write_buffer = 0;
    readbuf[0] = BC_ENTER_LOOPER;
    // 这里分析会改线程状态
    binder_write(bs, readbuf, sizeof(uint32_t));

    for (;;) {
        bwr.read_size = sizeof(readbuf);
        bwr.read_consumed = 0;
        bwr.read_buffer = (uintptr_t) readbuf;
        
        // 还是一样的逻辑
        res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);

        res = binder_parse(bs, 0, (uintptr_t) readbuf, bwr.read_consumed, func);
    
    }
}


// 一样的流程只是进入的是读的操作，没有写的数据了
static int binder_ioctl_write_read(struct file *filp,
				unsigned int cmd, unsigned long arg,
				struct binder_thread *thread)
{
	int ret = 0;
	// 拿binder_proc
	struct binder_proc *proc = filp->private_data;
	// 拿指令 这个是BINDER_WRITE_READ 用处不大，主要是移动指针
	unsigned int size = _IOC_SIZE(cmd);
	void __user *ubuf = (void __user *)arg;
	struct binder_write_read bwr;
   
   // 拷贝一份ubuf 到 bwr
	if (copy_from_user(&bwr, ubuf, sizeof(bwr))) {
		goto out;
	}
    ...
    
    // 这里进入这个里面
    if (bwr.read_size > 0) {
		ret = binder_thread_read(proc, thread, bwr.read_buffer,
					 bwr.read_size,
					 &bwr.read_consumed,
					 filp->f_flags & O_NONBLOCK);
		trace_binder_read_done(ret);
	}
}


static int binder_thread_read(struct binder_proc *proc,
			      struct binder_thread *thread,
			      binder_uintptr_t binder_buffer, size_t size,
			      binder_size_t *consumed, int non_block)
{
	void __user *buffer = (void __user *)(uintptr_t)binder_buffer;
	void __user *ptr = buffer + *consumed;
	void __user *end = buffer + size;

	int ret = 0;
	int wait_for_proc_work;


retry:
    // 如果线程事务栈和 todo 队列都为空，说明此时没有要当前线程处理的任务，将增加空闲线程的计数器（即将 wait_for_proc_work 设为1），让线程等待在**进程**的 wait 队列上
	wait_for_proc_work = thread->transaction_stack == NULL &&
				list_empty(&thread->todo);
    ···
    
    // 改变线程状态
	thread->looper |= BINDER_LOOPER_STATE_WAITING;
	if (wait_for_proc_work)
		proc->ready_threads++;

	binder_unlock(__func__);

	trace_binder_wait_for_work(wait_for_proc_work,
				   !!thread->transaction_stack,
				   !list_empty(&thread->todo));
	if (wait_for_proc_work) {
	    
		if (!(thread->looper & (BINDER_LOOPER_STATE_REGISTERED |
					BINDER_LOOPER_STATE_ENTERED))) {
			// 线程还未进入 binder 循环，输出错误信息，并阻塞直到 binder_stop_on_user_error 小于2
			wait_event_interruptible(binder_user_error_wait,
						 binder_stop_on_user_error < 2);
		}
		binder_set_nice(proc->default_priority);
		if (non_block) {
		    // 非阻塞
			if (!binder_has_proc_work(proc, thread))
				ret = -EAGAIN;
		} else
		    // 如果是阻塞的读操作，则让进程阻塞在 proc 的 wait 队列上，直到 binder_has_proc_work(thread) 为 true，即进程有工作待处理
			ret = wait_event_freezable_exclusive(proc->wait, binder_has_proc_work(proc, thread));
	} else {
	   ....
	}

	binder_lock(__func__);
    // 下面的逻辑需要等线程唤醒才能执行
    .....
	return 0;
}
```
小结：ServiceManager，首先注册成为管理者，然后binder_loop,改变线程状态，在线程没有任务的时候，阻塞在wait队列上

#### MediaService添加服务 
```c
status_t IPCThreadState::talkWithDriver(bool doReceive)
{
    do {
        // 不停的操作读写，跟Binder Driver进行通信
        if (ioctl(mProcess->mDriverFD, BINDER_WRITE_READ, &bwr) >= 0)
      ...
     } while (err == -EINTR); //当被中断，则继续执行
    
    return err;
}
```
包装的数据结构</br>
![包装的结构](https://github.com/TF27674569/Other-Data/blob/master/image/Binder_Data.png)</br>
还是进入的BINDER_WRITE_READ直接分析binder_ioctl_write_read
```c
static int binder_ioctl_write_read(struct file *filp,
                unsigned int cmd, unsigned long arg,
                struct binder_thread *thread)
{
    int ret = 0;
    // 从 filp 中获取 binder_proc 
    struct binder_proc *proc = filp->private_data;
    // arg 是上层传下来的 binder_write_read 的结构体对象地址
    void __user *ubuf = (void __user *)arg;
    struct binder_write_read bwr;

    // 将用户空间的 binder_write_read 拷贝到内核空间的 bwr
    if (copy_from_user(&bwr, ubuf, sizeof(bwr))) {
        ret = -EFAULT;
        goto out;
    }
    // write_size > 0 ，进入这里
    if (bwr.write_size > 0) {
        ret = binder_thread_write(proc, thread,
                      bwr.write_buffer,
                      bwr.write_size,
                      &bwr.write_consumed);
        trace_binder_write_done(ret);
    }
   
out:
    return ret;
}


// binder_thread_write分析过主要是看指令 BC_TRANSACTION
static int binder_thread_write(struct binder_proc *proc,
			struct binder_thread *thread,
			binder_uintptr_t binder_buffer, size_t size,
			binder_size_t *consumed)
{
	uint32_t cmd;
	void __user *buffer = (void __user *)(uintptr_t)binder_buffer;
	void __user *ptr = buffer + *consumed;
	void __user *end = buffer + size;

	while (ptr < end && thread->return_error == BR_OK) {
		switch (cmd) {
		...
		case BC_TRANSACTION:
		case BC_REPLY: {
			struct binder_transaction_data tr;
			// 拷贝一份到tr
			if (copy_from_user(&tr, ptr, sizeof(tr)))
				return -EFAULT;
			ptr += sizeof(tr);
			binder_transaction(proc, thread, &tr, cmd == BC_REPLY);
			break;
		}
	}
	return 0;
}

static void binder_transaction(struct binder_proc *proc,
			       struct binder_thread *thread,
			       struct binder_transaction_data *tr, int reply)
{
	struct binder_transaction *t;
	struct binder_work *tcomplete;
	binder_size_t *offp, *off_end;
	
    // 目标 target_proc，要找的是谁
	struct binder_proc *target_proc;
	// 目标 target_thread 
	struct binder_thread *target_thread = NULL;
	 // 目标 target_node 
	struct binder_node *target_node = NULL;
	struct list_head *target_list;
	wait_queue_head_t *target_wait;
	struct binder_transaction *in_reply_to = NULL;
	struct binder_transaction_log_entry *e;
	uint32_t return_error;

	e = binder_transaction_log_add(&binder_transaction_log);
	e->call_type = reply ? 2 : !!(tr->flags & TF_ONE_WAY);
	e->from_proc = proc->pid;
	e->from_thread = thread->pid;
	// handle 值，根据handler找
	e->target_handle = tr->target.handle;
	e->data_size = tr->data_size;
	e->offsets_size = tr->offsets_size;

	if (reply) {
		// 无应答数据
	} else {
	    // handler给的是0
		if (tr->target.handle) {
			...
		} else {
		    // target_node 是ServiceManager上下文管理的node
			target_node = binder_context_mgr_node;
			if (target_node == NULL) {
				return_error = BR_DEAD_REPLY;
				goto err_no_context_mgr_node;
			}
		}
	    // 这个就是ServiceManager
		target_proc = target_node->proc;
		...
	}
	if (target_thread) {
		...
	} else {
	    // todo队列和wait队列
		target_list = &target_proc->todo;
		target_wait = &target_proc->wait;
	}
	e->to_proc = target_proc->pid;

	// binder_transaction *t;
	t = kzalloc(sizeof(*t), GFP_KERNEL);
	
	// 无应答，不是oneway
	if (!reply && !(tr->flags & TF_ONE_WAY))
		t->from = thread;// Media线程
	else
		t->from = NULL;
	t->sender_euid = task_euid(proc->tsk);
	t->to_proc = target_proc;
	t->to_thread = target_thread;
	// tr->code = ADD_SERVICE_TRANSACTION
	t->code = tr->code;
	t->flags = tr->flags;
	t->priority = task_nice(current);

	trace_binder_transaction(reply, t, target_node);

    // 往 target_proc 中按需开辟内存，物理空间和内核空间映射同一块物理内存
	t->buffer = binder_alloc_buf(target_proc, tr->data_size,
		tr->offsets_size, !reply && (t->flags & TF_ONE_WAY));
	
	//  把数据拷贝到目标进程空间
	offp = (binder_size_t *)(t->buffer->data +
				 ALIGN(tr->data_size, sizeof(void *)));

	if (copy_from_user(t->buffer->data, (const void __user *)(uintptr_t)
			   tr->data.ptr.buffer, tr->data_size)) {
		binder_user_error("%d:%d got transaction with invalid data ptr\n",
				proc->pid, thread->pid);
		return_error = BR_FAILED_REPLY;
		goto err_copy_data_failed;
	}
	if (copy_from_user(offp, (const void __user *)(uintptr_t)
			   tr->data.ptr.offsets, tr->offsets_size)) {
		binder_user_error("%d:%d got transaction with invalid offsets ptr\n",
				proc->pid, thread->pid);
		return_error = BR_FAILED_REPLY;
		goto err_copy_data_failed;
	}

    
    
	off_end = (void *)offp + tr->offsets_size;
	for (; offp < off_end; offp++) {
		struct flat_binder_object *fp;
		// 从目标进程中获取 flat_binder_object 
		fp = (struct flat_binder_object *)(t->buffer->data + *offp);
		
		 // 判断 type ，这里是 BINDER_TYPE_BINDER
		switch (fp->type) {
		case BINDER_TYPE_BINDER:
		case BINDER_TYPE_WEAK_BINDER: {
			struct binder_ref *ref;
			
			
			 // 从自己的进程中获取 binder_node 节点
			struct binder_node *node = binder_get_node(proc, fp->binder);
			if (node == NULL) {
			    // 根据 fp->binder 创建一个新的 binder_node 
				node = binder_new_node(proc, fp->binder, fp->cookie);
				if (node == NULL) {
					return_error = BR_FAILED_REPLY;
					goto err_binder_new_node_failed;
				}
			}
			
			 // 根据  binder_node 节点从目标进程中获取 binder_ref
			ref = binder_get_ref_for_node(target_proc, node);
			if (ref == NULL) {
				return_error = BR_FAILED_REPLY;
				goto err_binder_get_ref_for_node_failed;
			}
			
			// 替换type
			if (fp->type == BINDER_TYPE_BINDER)
				fp->type = BINDER_TYPE_HANDLE;
			else
				fp->type = BINDER_TYPE_WEAK_HANDLE;
				
			// 赋值handler值
			fp->handle = ref->desc;
			binder_inc_ref(ref, fp->type == BINDER_TYPE_HANDLE,
				       &thread->todo);

			trace_binder_transaction_node_to_ref(t, node, ref);
		} break;
		
	// 往目标进程中添加一个 BINDER_WORK_TRANSACTION
	t->work.type = BINDER_WORK_TRANSACTION;
	list_add_tail(&t->work.entry, target_list);
	// 自己进程中添加一个 BINDER_WORK_TRANSACTION_COMPLETE
	tcomplete->type = BINDER_WORK_TRANSACTION_COMPLETE;
	list_add_tail(&tcomplete->entry, &thread->todo);
	if (target_wait)
	    // 唤醒target_wait队列
		wake_up_interruptible(target_wait);
	return;
```

##### ServiceManager被唤醒处理请求
```c
static int binder_thread_read(struct binder_proc *proc,
                  struct binder_thread *thread,
                  binder_uintptr_t binder_buffer, size_t size,
                  binder_size_t *consumed, int non_block)
{
    // todo 里面有数据了等等被唤醒
    binder_lock(__func__);

    if (wait_for_proc_work)
        proc->ready_threads--;
    thread->looper &= ~BINDER_LOOPER_STATE_WAITING;

    if (ret)
        return ret;
    // 开始不断循环读取数据 
    while (1) {
        uint32_t cmd;
        struct binder_transaction_data tr;
        struct binder_work *w;
        struct binder_transaction *t = NULL;
    
        if (!list_empty(&thread->todo)) {
            ...
        } else if (!list_empty(&proc->todo) && wait_for_proc_work) {
            // 获取 todo 队列中的第一条
            w = list_first_entry(&proc->todo, struct binder_work,
                         entry);
        } else {
            ...
        }

        switch (w->type) {
        case BINDER_WORK_TRANSACTION: {
            // 进入这个分支
            t = container_of(w, struct binder_transaction, work);
        } break;
        ...
        }

        if (!t)
            continue;

        if (t->buffer->target_node) {
            // 解析参数
            struct binder_node *target_node = t->buffer->target_node;
            tr.target.ptr = target_node->ptr;
            tr.cookie =  target_node->cookie;
            cmd = BR_TRANSACTION;
        } else {
            ...
        }
        tr.code = t->code;
        tr.flags = t->flags;
        tr.sender_euid = from_kuid(current_user_ns(), t->sender_euid);
        // 解析 data 数据
        tr.data_size = t->buffer->data_size;
        tr.offsets_size = t->buffer->offsets_size;
        tr.data.ptr.buffer = (binder_uintptr_t)(
                    (uintptr_t)t->buffer->data +
                    proc->user_buffer_offset);
        tr.data.ptr.offsets = tr.data.ptr.buffer +
                    ALIGN(t->buffer->data_size,
                        sizeof(void *));
        // 写入命令
        if (put_user(cmd, (uint32_t __user *)ptr))
            return -EFAULT;
        ptr += sizeof(uint32_t);
        //  把数据拷贝到用户空间
        if (copy_to_user(ptr, &tr, sizeof(tr)))
            return -EFAULT;
        ptr += sizeof(tr);
        // 从 todo 队列中移除
        list_del(&t->work.entry);
        break;
    }

done:
    ...
    return 0;
}
```

